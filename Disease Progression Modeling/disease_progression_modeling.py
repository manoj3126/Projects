# -*- coding: utf-8 -*-
"""Disease Progression Modeling.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1unom4ZeA7OJLCnmN4zKYm5mH5-nNzMuE
"""

# step1: Import Librariese

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.metrics import mean_squared_error, r2_score

# step2: Generate synthesis healthcare dataset

np.random.seed(42)
n=500

age = np.random.randint(20,80,n)
bmi = np.random.normal(27,5,n)
insulin = np.random.normal(20,5,n)
exercise = np.random.randint(0,7,n)

# True Relationship (non-linear + intractions)
hba1c = (
    5 + 0.02*age + 0.1*bmi - 0.05*exercise
    + 0.03*age*(bmi/30)                        # interaction
    + 0.002*bmi**2                             # non-linear
    - 0.01*insulin + np.random.normal(0, 0.5, n)  # noise
)
# put in the dataframe
data = pd.DataFrame({
    "Age":age,
    "BMI":bmi,
    "Insulin":insulin,
    "Exercise":exercise,
    "HbA1c":hba1c
    })
print(data.head())
print(data.shape)

# Step3: Train test split
x= data[["Age","BMI","Insulin","Exercise"]]
y= data["HbA1c"]
x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=42)

# step4: Baseline linear regression
lr = LinearRegression()
lr.fit(x_train,y_train)

y_pred_lr = lr.predict(x_test)

print("Linear Regression R²:", r2_score(y_test, y_pred_lr))
print("Linear Regression RMSE:", np.sqrt(mean_squared_error(y_test, y_pred_lr)))

# step5: polynomial + Intraction Features

poly = PolynomialFeatures(degree=2, include_bias=False)
X_poly = poly.fit_transform(x)

X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(X_poly, y, test_size=0.2, random_state=42)

lr_poly = LinearRegression()
lr_poly.fit(X_train_p, y_train_p)
y_pred_poly = lr_poly.predict(X_test_p)

print("Poly Regression R²:", r2_score(y_test_p, y_pred_poly))
print("Poly Regression RMSE:", np.sqrt(mean_squared_error(y_test_p, y_pred_poly)))

# Step6: Regularization (Ridge, Lasso, ElasticNet)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train_p)
X_test_scaled = scaler.transform(X_test_p)

ridge = Ridge(alpha=1.0)
ridge.fit(X_train_scaled, y_train_p)
print("Ridge R²:", r2_score(y_test_p, ridge.predict(X_test_scaled)))

lasso = Lasso(alpha=0.01, max_iter=5000)
lasso.fit(X_train_scaled, y_train_p)
print("Lasso R²:", r2_score(y_test_p, lasso.predict(X_test_scaled)))

elastic = ElasticNet(alpha=0.01, l1_ratio=0.5, max_iter=5000)
elastic.fit(X_train_scaled, y_train_p)
print("ElasticNet R²:", r2_score(y_test_p, elastic.predict(X_test_scaled)))

# Step7: Feature Importance (from Lasso)
feature_names = poly.get_feature_names_out(x.columns)
coeffs = pd.DataFrame({
    "Feature": feature_names,
    "Coefficient": lasso.coef_
})
print(coeffs[coeffs["Coefficient"] != 0].sort_values(by="Coefficient", ascending=False))

